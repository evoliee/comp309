{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f28574a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3211e095",
   "metadata": {},
   "source": [
    "an encoder, which takes the 2-d inputs and produces a 1-dimensional z via a weighted sum plus a bias. The\n",
    "encoder weights will be a 1-by-2 tensor and the encoder bias will be a 1-by-1 tensor.\n",
    "\n",
    "• a decoder, which just does the reverse: it takes that 1-dim z and produces a 2-dim output via a weighting of\n",
    "z plus a bias (see the equation in the figure). (Note: decoding is not to be confused with the torch’s backward()\n",
    "operation that propagates gradients! This is a still ”forwards” transformation).\n",
    "\n",
    "• a loss function, which should be the mean squared error (MSE) between x and its reconstruction, averaged\n",
    "over the data set.\n",
    "\n",
    "By using autograd (.backward()) and optimising the MSE loss, you will learn the values of the weights and biases\n",
    "in the encoder, and the decoder (i.e. 3 parameters in the encoder and 4 in the decoder). For each run of learning,\n",
    "start from random weights and biases, such as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b05581b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wEncoder = torch.randn(D,1, requires_grad=True)\n",
    "wDecoder = torch.randn(1,D, requires_grad=True)\n",
    "bEncoder = torch.randn(1, requires_grad=True)\n",
    "bDecoder = torch.randn(1,D, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c8cd42",
   "metadata": {},
   "source": [
    "Requirements\n",
    "1. Use SGD, learning rate 0.01, no momentum, and 1000 steps (from a random start).\n",
    "    • Plot the loss versus epochs (steps).\n",
    "    • All on the same axes of one scatterplot, show (i) the original data in some light colour like ‘cyan‘, \n",
    "                                                    (ii) the reconstructed data in a different colour, and (iii) a line from the origin to vector formed by the two learned encoder weights. Perhaps something like...\n",
    "            plt.scatter(x[:,0],x[:,1],color=’cyan’);\n",
    "            plt.scatter(x_reconstruction.detach()[:,0],x_reconstruction.detach()[:,1]);\n",
    "            plt.plot([0,wEncoder[0,0]], [0,wEncoder[1,0]],’-r’);\n",
    "            plt.axis(’equal’)\n",
    "    • print out the ratio of the weight in the encoder versus the weight in the decoder, for each of the two\n",
    "dimensions.\n",
    "2. Now add momentum (say 0.9) and do the same (from a random start).\n",
    "3. Switch to RMSprop (with momentum 0.9 and a random start) and do the same.\n",
    "4. In a text cell of the notebook, write a couple of concise paragraphs, interpreting what you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "261c175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6598, 1.7740],\n",
      "        [1.2147, 1.0764],\n",
      "        [1.2096, 1.1302],\n",
      "        [1.3266, 1.0310],\n",
      "        [1.0027, 0.9998],\n",
      "        [0.7485, 0.8707],\n",
      "        [0.3699, 0.4888],\n",
      "        [0.4615, 0.4938],\n",
      "        [0.8153, 0.8595],\n",
      "        [0.7738, 0.8514],\n",
      "        [1.2300, 0.9309],\n",
      "        [1.5266, 1.3877],\n",
      "        [0.2506, 0.1644],\n",
      "        [0.7914, 0.5390],\n",
      "        [1.8036, 1.8123],\n",
      "        [0.6254, 0.7365],\n",
      "        [0.6705, 0.3963],\n",
      "        [1.1030, 1.2104],\n",
      "        [0.9933, 0.5888],\n",
      "        [1.3294, 1.1020],\n",
      "        [1.0926, 1.4379],\n",
      "        [0.7814, 1.1592],\n",
      "        [1.1067, 1.5062],\n",
      "        [1.2353, 1.0036],\n",
      "        [1.2316, 1.3467],\n",
      "        [0.8983, 0.9971],\n",
      "        [1.4661, 1.4719],\n",
      "        [1.5992, 1.5370],\n",
      "        [0.4104, 0.3242],\n",
      "        [0.7184, 0.7424],\n",
      "        [0.9702, 0.6283],\n",
      "        [1.0320, 1.0675],\n",
      "        [0.8352, 0.6794],\n",
      "        [0.2618, 0.1801],\n",
      "        [1.4006, 1.3996],\n",
      "        [1.3445, 1.6432],\n",
      "        [0.5854, 0.3147],\n",
      "        [0.8440, 0.8035],\n",
      "        [1.6051, 1.5227],\n",
      "        [0.5681, 0.4484],\n",
      "        [0.5885, 0.7291],\n",
      "        [0.1956, 0.1848],\n",
      "        [1.2523, 1.5046],\n",
      "        [1.2952, 1.6000],\n",
      "        [1.5900, 1.6738],\n",
      "        [0.3843, 0.2137],\n",
      "        [1.3012, 1.2168],\n",
      "        [1.2997, 1.6007],\n",
      "        [1.1931, 1.3232],\n",
      "        [1.0791, 0.8736],\n",
      "        [1.4782, 1.6597],\n",
      "        [0.9242, 0.6864],\n",
      "        [1.3963, 1.2844],\n",
      "        [1.0858, 0.8648],\n",
      "        [1.4493, 1.6785],\n",
      "        [1.7584, 1.6697],\n",
      "        [1.4088, 1.5905],\n",
      "        [0.7204, 0.4109],\n",
      "        [0.9672, 0.8370],\n",
      "        [1.4687, 1.2174],\n",
      "        [1.2775, 1.1575],\n",
      "        [0.7421, 0.5273],\n",
      "        [0.2787, 0.3331],\n",
      "        [0.5945, 0.7068],\n",
      "        [0.5072, 0.5204],\n",
      "        [1.2815, 0.9925],\n",
      "        [1.8471, 1.7808],\n",
      "        [0.8331, 0.8599],\n",
      "        [1.2064, 0.8625],\n",
      "        [1.2462, 1.5554],\n",
      "        [1.1570, 1.1617],\n",
      "        [0.9938, 0.8981],\n",
      "        [0.6075, 0.3152],\n",
      "        [0.8986, 0.7321],\n",
      "        [0.8879, 0.9123],\n",
      "        [0.3690, 0.5369],\n",
      "        [1.1875, 1.3721],\n",
      "        [1.0286, 0.9411],\n",
      "        [1.1101, 0.8663],\n",
      "        [0.3951, 0.3396],\n",
      "        [0.9614, 1.3130],\n",
      "        [0.5527, 0.6496],\n",
      "        [0.7314, 0.6194],\n",
      "        [0.9245, 1.0010],\n",
      "        [0.2124, 0.1515],\n",
      "        [0.6201, 0.7371],\n",
      "        [0.7762, 0.9441],\n",
      "        [0.5952, 0.8430],\n",
      "        [1.8439, 1.8065],\n",
      "        [1.1994, 0.9315],\n",
      "        [0.6110, 0.7846],\n",
      "        [1.0055, 1.2717],\n",
      "        [0.8386, 1.1294],\n",
      "        [0.5749, 0.6930],\n",
      "        [0.9980, 1.0645],\n",
      "        [0.4828, 0.3933],\n",
      "        [1.3996, 1.1893],\n",
      "        [0.6514, 0.3974],\n",
      "        [0.3541, 0.4557],\n",
      "        [0.8206, 0.9372]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set up\n",
    "torch.manual_seed(309)\n",
    "np.random.seed(309)\n",
    "\n",
    "# make up some data for x\n",
    "D = 2\n",
    "x= torch.rand(100,D)\n",
    "x[:,0] = x[:,0] + x[:,1]\n",
    "x[:,1] = 0.5*x[:,0] + x[:,1]\n",
    "plt.scatter(x[:,0],x[:,1])\n",
    "plt.axis('equal')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab1c65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder thingy\n",
    "class Autoencoder(torch.nn.Module):   \n",
    "    def __init__(self):\n",
    "        super().__init__()    \n",
    "        # Applies a linear transformation to the incoming data: \n",
    "        # w/o additive bias\n",
    "        self.encoder = torch.nn.Linear(1*2, 1, False) \n",
    "        self.decoder = torch.nn.Linear(1, 1*2, False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        en = self.encoder(x)\n",
    "        de = self.decoder(en)\n",
    "        return de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dd6c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up model\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "wEncoder = torch.randn(D,1, requires_grad=True)\n",
    "wDecoder = torch.randn(1,D, requires_grad=True)\n",
    "bEncoder = torch.randn(1, requires_grad=True)\n",
    "bDecoder = torch.randn(1,D, requires_grad=True)\n",
    "\n",
    "model = Autoencoder()\n",
    "model.encoder.weight = torch.nn.Parameter(wEncoder)\n",
    "model.decoder.weight = torch.nn.Parameter(wDecoder)\n",
    "model.encoder.bias   = torch.nn.Parameter(bEncoder[0])\n",
    "model.decoder.bias   = torch.nn.Parameter(bDecoder[0])\n",
    "\n",
    "sgd = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84109714",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (100x2 and 1x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m loss_history    \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[1;32m----> 7\u001b[0m     reconstruction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     thisEpochsLoss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss(reconstruction, x)\n\u001b[0;32m     10\u001b[0m     sgd\u001b[38;5;241m.\u001b[39mzero_grad() \n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mAutoencoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 11\u001b[0m     en \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     de \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(en)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m de\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x2 and 1x2)"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "epoch = 0\n",
    "x_reconstructed = []\n",
    "loss_history    = []\n",
    "\n",
    "for epoch in range(N):\n",
    "    reconstruction = model.forward(x)\n",
    "    thisEpochsLoss = torch.nn.MSELoss(reconstruction, x)\n",
    "\n",
    "    sgd.zero_grad() \n",
    "    thisEpochsLoss.backward() \n",
    "    sgd.step()    \n",
    "\n",
    "    # if last epoch\n",
    "    if (epoch == N-1): x_reconstructed.append(reconstruction.detach())\n",
    "    loss_history.append(loss.item())\n",
    "wEncoder = model.encoder.weight\n",
    "wDecoder = model.decoder.weight\n",
    "weightRatio = wEn[0]/wDe[0]\n",
    "\n",
    "print(\"W0_Ratio:\"  , round(weightRatio[0].item(), 3), \n",
    "      \"\\nW1_Ratio:\", round(weightRatio[1].item(), 3), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(20, 8), dpi=80)\n",
    "plt.tight_layout(pad = 8.0)\n",
    "\n",
    "ax[0].scatter(x[:,0], x[:,1], s=6.5, color='cyan');          #Original\n",
    "ax[0].scatter(x_recons[0][:,0], x_recons[0][:,1], s=6.5) #Reconstructed\n",
    "ax[0].plot([0,wEncoder.T.detach()[0,0]], [0,wEncoder.T.detach()[1,0]],'-r') #Initial encoder wgt\n",
    "\n",
    "ax[0].set(title = 'Original vs Reconstruction', xlabel = 'x', ylabel = 'y')\n",
    "ax[0].axis('equal')\n",
    "\n",
    "ax[1].plot(losses) #Loss overtime\n",
    "ax[1].set(title = 'Loss vs Epochs(steps)', xlabel = 'Epochs', ylabel = 'Loss')\n",
    "\n",
    "plt.show()          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
